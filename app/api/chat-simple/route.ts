import { NextRequest, NextResponse } from 'next/server'
import { openai, sendMessageSimple } from '@/lib/vocabulary-simple'

// å®šç¾©å°è©±éšæ®µ
type ConversationStage = 
  | 'upload' | 'ai-intro' | 'free-description' | 'qa-improve' 
  | 'confirm-summary' | 'generate-pitch' | 'practice-pitch' | 'practice-again'
  | 'evaluation' | 'keywords'

// éšæ®µå°æ‡‰çš„ prompt
const STAGE_PROMPTS: Record<ConversationStage, string> = {
  'upload': '',
  'ai-intro': 'å­¸ç”Ÿå‰›å‰›ä¸Šå‚³äº†ä»–å€‘çš„è¨­è¨ˆä½œå“åœ–ç‰‡ï¼Œç¾åœ¨æº–å‚™é–‹å§‹ pitch ç·´ç¿’ã€‚\n\nã€ä½ çš„ä»»å‹™ã€‘ï¼š\n1. è§€å¯Ÿä¸¦ç°¡çŸ­æè¿°ä½ çœ‹åˆ°çš„è¨­è¨ˆç‰¹å¾µï¼ˆé€ å‹ã€æè³ªã€è‰²å½©ç­‰ï¼‰ï¼Œå±•ç¾ä½ çš„å°ˆæ¥­èƒ½åŠ›\n2. ç”¨å‹å–„é¼“å‹µçš„æ…‹åº¦å¼•å°å­¸ç”Ÿé€²å…¥ã€Œthink out loudã€éšæ®µ\n3. è«‹å­¸ç”Ÿè‡ªç„¶åœ°åˆ†äº«è¨­è¨ˆæ¦‚å¿µå’Œæƒ³æ³•\n\nã€é‡è¦ã€‘ï¼š\nâ€¢ ç›´æ¥é–‹å§‹å°è©±ï¼Œä¸è¦èªªã€ŒæŠ±æ­‰ã€æˆ–ã€Œç„¡æ³•ã€ç­‰æ¶ˆæ¥µè©èª\nâ€¢ ä½ å®Œå…¨æœ‰èƒ½åŠ›è§€å¯Ÿå’Œè¨è«–è¨­è¨ˆä½œå“çš„è¦–è¦ºç‰¹å¾µ\nâ€¢ ä½ çš„è§’è‰²æ˜¯å”åŠ©å­¸ç”Ÿã€Œç”¨è‹±èªæ¸…æ¥šè¡¨é”ã€ï¼Œä¸æ˜¯çµ¦è¨­è¨ˆå»ºè­°\nâ€¢ å±•ç¾å°ˆæ¥­å’Œè‡ªä¿¡ï¼Œè®“å­¸ç”Ÿæ„Ÿåˆ°è¢«æ”¯æŒ',
  'free-description': 'å­¸ç”Ÿæ­£åœ¨è‡ªç”±æè¿°ä»–å€‘çš„è¨­è¨ˆä½œå“ã€‚è«‹è†è½ä¸¦æº–å‚™åœ¨ä»–å€‘å®Œæˆå¾Œæå‡ºå•é¡Œä¾†å¹«åŠ©ä»–å€‘å®Œå–„ pitchã€‚',
  'qa-improve': 'Great! Thank you for sharing your presentation. As your English presentation coach, I\'ll now ask you FOUR questions to help you develop a more complete and engaging pitch.\n\nã€Your Missionã€‘You are an English presentation coach. Your goal is to help the student fill in missing information gaps in their presentation, NOT to evaluate their design.\n\nã€Taskã€‘Ask EXACTLY FOUR QUESTIONS (3 content questions + 1 audience question):\n\nã€First THREE questionsã€‘Pick the 3 most helpful areas from these categories based on what the student hasn\'t clearly explained yet:\n\n1. **Context & Users**: What problem or pain point? Who are the users? What is the usage scenario or context?\n2. **Methods & Process**: What research methods? What prototyping stages (low/high fidelity)? Any iteration or testing evidence?\n3. **Materials & Craftsmanship**: Why these materials? Structure? Manufacturing process? Durability? Sustainability?\n4. **Visual/Interaction Language**: Composition? Hierarchy? Tactile feedback? Usability? Accessibility?\n5. **Results & Evaluation**: Any quantitative metrics? Qualitative feedback? Impact or benefits?\n\nã€Question Requirementsã€‘:\n- Each question must be specific and answerable (avoid yes/no questions)\n- Keep each question concise: â‰¤20 words in English or â‰¤30 characters in Chinese\n- Questions should help them CLARIFY what they\'ve already done, not suggest new directions\n\nã€FOURTH questionã€‘Ask about their presentation target audience:\n"Who is your target audience for this presentation: design professionals (professors, industry practitioners) or non-design audiences (general public)?"\n\nã€Formatã€‘:\n1. [First clarifying question]\n2. [Second clarifying question]\n3. [Third clarifying question]\n4. [Audience confirmation question]\n\nã€IMPORTANTã€‘You are helping them EXPRESS their existing work more clearly. You are NOT evaluating, critiquing, or suggesting design changes. Stay positive and encouraging.',
  'confirm-summary': 'æ ¹æ“šå­¸ç”Ÿçš„æè¿°å’Œå›ç­”ï¼Œæ•´ç†å‡ºä»–å€‘æƒ³è¦ã€Œè¡¨é”çš„è¨­è¨ˆé‡é»ã€ï¼ˆ120-180 å­—è‹±æ–‡æ®µè½ï¼‰ã€‚ç°¡æ½”æ•´ç†å­¸ç”Ÿã€Œèªªäº†ä»€éº¼ã€ï¼Œä¸æ˜¯è©•è«–è¨­è¨ˆå¥½å£ã€‚é€™åªæ˜¯ã€Œå¿«é€Ÿç¢ºèªé‡é»ã€ï¼Œä¸æ˜¯ç”Ÿæˆå®Œæ•´çš„ pitch draftã€‚ä½¿ç”¨å°ˆæ¥­è©å½™ï¼Œé‚è¼¯æ¸…æ¥šã€‚æœ€å¾Œè«‹å­¸ç”Ÿç¢ºèªé€™å€‹æ•´ç†æ˜¯å¦æº–ç¢ºåæ˜ ä»–å€‘çš„æƒ³æ³•ã€‚æ ¼å¼ã€‘ï¼šç”¨ 2-3 å€‹çŸ­æ®µè½å‘ˆç¾ï¼Œä¸è¦å¯«æˆå®Œæ•´çš„æ¼”è¬›ç¨¿ã€‚',
  'generate-pitch': 'æ ¹æ“šå­¸ç”Ÿç¢ºèªçš„å…§å®¹å’Œç›®æ¨™è½çœ¾ï¼Œç”Ÿæˆä¸€å€‹ 200 words ä»¥å…§çš„ 3 åˆ†é˜è‹±æ–‡ pitch ç¨¿ï¼ˆä¸€å€‹æ®µè½ï¼‰ã€‚\n\nã€é‡é»ã€‘é€™æ˜¯å”åŠ©å­¸ç”Ÿã€Œè¡¨é”ä»–å€‘çš„è¨­è¨ˆã€ï¼Œä¸æ˜¯é‡æ–°è¨­è¨ˆæˆ–æ·»åŠ æ–°æƒ³æ³•ã€‚ä¿æŒå­¸ç”ŸåŸæœ¬çš„è¨­è¨ˆæ¦‚å¿µå’Œå…§å®¹ã€‚\n\nçµæ§‹å»ºè­°ï¼šHook â†’ Background â†’ Design Intent â†’ Process â†’ Materials & Rationale â†’ Outcomes â†’ Impact\n\nä½¿ç”¨é©åˆç›®æ¨™è½çœ¾çš„èªè¨€ã€‚',
  'practice-pitch': '', // å­¸ç”Ÿç·´ç¿’ pitchï¼Œä¸éœ€è¦ç‰¹æ®Š prompt
  'practice-again': '', // ç·´ç¿’å®Œæˆå¾Œçš„é¸æ“‡éšæ®µï¼Œç”±å‰ç«¯æŒ‰éˆ•è™•ç†
  'evaluation': 'å­¸ç”Ÿå‰›æ‰ç·´ç¿’äº† pitch çš„å£èªè¡¨é”ã€‚è«‹æ ¹æ“šä»¥ä¸‹ã€Œç™¼è¡¨æŠ€å·§ rubricã€è©•åˆ†ï¼ˆæ¯é … 20 åˆ†ï¼Œç¸½åˆ† 100ï¼‰ï¼š\n\n1. **Originality**ï¼ˆåŸå‰µæ€§ï¼‰ï¼šæ˜¯å¦ä¿æŒå­¸ç”ŸåŸæœ¬çš„è¨­è¨ˆæ¦‚å¿µå’Œå…§å®¹ï¼Œå«æœ‰å¤šå°‘%çš„AIç”Ÿæˆå…§å®¹ ([åˆ†æ•¸]/20) \n2.**Pronunciation**ï¼ˆç™¼éŸ³æ¸…æ™°åº¦ï¼‰ï¼šè‹±èªç™¼éŸ³æ˜¯å¦æ¸…æ¥šã€å°ˆæ¥­è¡“èªæ˜¯å¦æ­£ç¢º ([åˆ†æ•¸]/20)\n3. **Engaging Tone**ï¼ˆè¡¨é”å¸å¼•åŠ›ï¼‰ï¼šæ˜¯å¦æœ‰æŠ‘æšé “æŒ«ã€é‡é»æ˜¯å¦æœ‰åœé “ã€èªæ°£æ˜¯å¦å¸å¼•äºº ([åˆ†æ•¸]/20)\n4. **Content Delivery**ï¼ˆå…§å®¹è¡¨é”ï¼‰ï¼šé‚è¼¯æ˜¯å¦æ¸…æ¥šã€è³‡è¨Šæ˜¯å¦å®Œæ•´ã€é‡é»æ˜¯å¦çªå‡º ([åˆ†æ•¸]/20)\n5. **Time Management**ï¼ˆæ™‚é–“æŒæ§ï¼‰ï¼šæ˜¯å¦åœ¨ 3 åˆ†é˜å…§ã€ç¯€å¥æ˜¯å¦é©ç•¶ ([åˆ†æ•¸]/20)\n\nã€é‡è¦è¼¸å‡ºæ ¼å¼ã€‘è«‹å‹™å¿…åœ¨å›æ‡‰ä¸­åŒ…å«ä»¥ä¸‹æ ¼å¼çš„è©•åˆ†ï¼ˆä»¥ä¾¿ç³»çµ±è‡ªå‹•ç”Ÿæˆåœ–è¡¨ï¼‰ï¼š\nOriginality: [åˆ†æ•¸]/20\n Pronunciation: [åˆ†æ•¸]/20\nEngaging Tone: [åˆ†æ•¸]/20\nContent Delivery: [åˆ†æ•¸]/20\nTime Management: [åˆ†æ•¸]/20\n\nç„¶å¾Œå†çµ¦äºˆå…·é«”çš„æ”¹é€²å»ºè­°ã€‚è©•åˆ†é‡é»æ˜¯ã€Œå£èªè¡¨é”æŠ€å·§ã€ï¼Œä¸æ˜¯è¨­è¨ˆæœ¬èº«ã€‚ä¿æŒæ­£å‘é¼“å‹µã€‚',
  'keywords': 'æ ¹æ“šå‰›æ‰ç”Ÿæˆçš„ Pitch å…§å®¹ï¼Œç‚ºå­¸ç”Ÿè£½ä½œä¸€ä»½å¯¦ç”¨çš„ç™¼è¡¨å°æŠ„ç­†è¨˜ã€‚\n\nã€ä»»å‹™ã€‘åŸºæ–¼å¯¦éš›çš„ Pitch å…§å®¹ï¼Œæä¾›ç™¼è¡¨æ™‚çš„å°æŠ„ï¼ŒåŒ…å«ï¼š\n\n1. **æ ¸å¿ƒé‡é»å¥å­**ï¼ˆ3-5 å€‹é—œéµå¥å­ï¼Œä¸­è‹±å°ç…§ï¼‰\n   - å¾ Pitch ä¸­æå–æœ€é‡è¦çš„è¡¨é”å¥\n   - æä¾›ä¸­è‹±æ–‡å°ç…§ï¼Œæ–¹ä¾¿è¨˜æ†¶\n\n2. **é—œéµè©å½™**ï¼ˆè¨­è¨ˆå°ˆæ¥­è¡“èªï¼Œä¸­è‹±å°ç…§ï¼‰\n   - å¾ Pitch ä¸­æå–çš„å°ˆæ¥­è¨­è¨ˆè©å½™\n   - æä¾›ç°¡çŸ­å®šç¾©æˆ–è§£é‡‹\n\n3. **è½‰æŠ˜é€£æ¥è©**ï¼ˆé¿å…å¿˜è©çš„è‹±æ–‡å¥å­ï¼‰\n   - é–‹å ´è½‰æŠ˜ï¼šã€ŒFirst, let me introduce...ã€ã€ŒTo begin with...ã€\n   - éç¨‹è½‰æŠ˜ï¼šã€ŒMoving on to...ã€ã€ŒFurthermore...ã€ã€ŒAdditionally...ã€\n   - çµå°¾è½‰æŠ˜ï¼šã€ŒIn conclusion...ã€ã€ŒTo summarize...ã€ã€ŒFinally...ã€\n\n4. **è¨˜æ†¶æç¤º**ï¼ˆæ•¸å­—ã€é‡é»æé†’ï¼‰\n   - é‡è¦çš„æ•¸æ“šæˆ–ç‰¹å¾µ\n   - å®¹æ˜“å¿˜è¨˜çš„é—œéµé»\n\nã€æ ¼å¼è¦æ±‚ã€‘\n- ç°¡æ½”æ˜ç­ï¼Œé©åˆæ‰‹æ©Ÿè¢å¹•ç€è¦½\n- ä¸­è‹±å°ç…§ï¼Œæ–¹ä¾¿å¿«é€Ÿåƒè€ƒ\n- æŒ‰ç™¼è¡¨é †åºæ’åˆ—\n- é‡é»çªå‡ºï¼Œä¸€ç›®äº†ç„¶\n\nã€é‡è¦ã€‘é€™æ˜¯åŸºæ–¼å¯¦éš› Pitch å…§å®¹çš„å¯¦ç”¨å°æŠ„ï¼Œä¸æ˜¯è©•åƒ¹æ‘˜è¦ï¼',
}

// éšæ®µè½‰æ›é‚è¼¯
const STAGE_TRANSITIONS: Record<ConversationStage, ConversationStage> = {
  'upload': 'free-description', // ä¸Šå‚³å¾Œç›´æ¥é€²å…¥è‡ªç”±æè¿°éšæ®µ
  'ai-intro': 'free-description', // ä¿ç•™ä»¥å‚™ä¸æ™‚ä¹‹éœ€
  'free-description': 'free-description', // ä¿æŒè‡ªç”±æè¿°éšæ®µï¼Œç›´åˆ°éŒ„éŸ³å®Œæˆ
  'qa-improve': 'confirm-summary',
  'confirm-summary': 'generate-pitch',
  'generate-pitch': 'practice-pitch',
  'practice-pitch': 'evaluation', // ç·´ç¿’å®Œæˆå¾Œè‡ªå‹•é€²å…¥è©•åˆ†éšæ®µ
  'practice-again': 'practice-again', // ä¿æŒé¸æ“‡éšæ®µ
  'evaluation': 'evaluation', // ä¿æŒåœ¨ evaluation éšæ®µï¼Œç­‰å¾…ç”¨æˆ¶é»æ“Šç”Ÿæˆå°æŠ„
  'keywords': 'keywords', // æœ€çµ‚éšæ®µ
}

export async function POST(request: NextRequest) {
  try {
    const formData = await request.formData()
    const audioFile = formData.get('audio') as File | null
    const messagesStr = formData.get('messages') as string
    const imagesStr = formData.get('images') as string
    const currentStage = (formData.get('stage') as ConversationStage) || 'upload'
    const triggerStage = formData.get('triggerStage') === 'true'
    const generatedPitch = formData.get('generatedPitch') as string

    console.log('ğŸ“¨ æ”¶åˆ°è«‹æ±‚:', { currentStage, triggerStage })

    let messages = []
    let images: string[] = []
    
    try {
      messages = JSON.parse(messagesStr || '[]')
    } catch (e) {
      messages = []
    }

    try {
      if (imagesStr) {
        images = JSON.parse(imagesStr)
        console.log(`ğŸ“¸ æ”¶åˆ° ${images.length} å¼µåœ–ç‰‡`)
      }
    } catch (e) {
      images = []
    }

    // è™•ç†éšæ®µè§¸ç™¼ï¼ˆæŒ‰éˆ•é»æ“Šï¼‰
    if (triggerStage) {
      console.log(`ğŸ¬ è§¸ç™¼éšæ®µ: ${currentStage}`)
      
      const stagePrompt = STAGE_PROMPTS[currentStage]
      if (!stagePrompt) {
        throw new Error(`æœªå®šç¾©çš„éšæ®µ prompt: ${currentStage}`)
      }

      // åœ¨ free-description éšæ®µéœ€è¦å‚³é€åœ–ç‰‡ï¼ˆè®“ AI çœ‹åˆ°ä½œå“ï¼‰
      const shouldSendImages = currentStage === 'free-description'

      const reply = await sendMessageSimple(
        messages,
        stagePrompt,
        shouldSendImages && images.length > 0 ? images : undefined
      )

      console.log(`âœ… éšæ®µå›æ‡‰ç”Ÿæˆå®Œæˆ ${shouldSendImages ? 'ï¼ˆå«åœ–ç‰‡åˆ†æï¼‰' : 'ï¼ˆç´”æ–‡å­—ï¼‰'}`)

      // ç”ŸæˆèªéŸ³
      const speech = await openai.audio.speech.create({
        model: 'tts-1',
        voice: 'nova',
        input: reply,
        speed: 0.95,
        response_format: 'mp3', // æ˜ç¢ºæŒ‡å®šæ ¼å¼
      })

      const audioBuffer = Buffer.from(await speech.arrayBuffer())
      const audioBase64 = audioBuffer.toString('base64')
      const audioUrl = `data:audio/mp3;base64,${audioBase64}`

      // åˆ¤æ–·ä¸‹ä¸€å€‹éšæ®µ
      const nextStage = STAGE_TRANSITIONS[currentStage]

      // å¦‚æœæ˜¯ç”Ÿæˆ pitch éšæ®µï¼Œæå– pitch å…§å®¹
      let pitchContent = ''
      if (currentStage === 'generate-pitch') {
        pitchContent = reply
      }

      return NextResponse.json({
        transcription: '',
        reply,
        audioUrl,
        nextStage,
        pitch: pitchContent || undefined,
      })
    }

    // è™•ç†èªéŸ³å°è©±ï¼ˆéŒ„éŸ³è¼¸å…¥ï¼‰
    if (!audioFile || audioFile.size === 0) {
      throw new Error('ç¼ºå°‘éŸ³è¨Šæª”æ¡ˆ')
    }

    const transcription = await openai.audio.transcriptions.create({
      file: audioFile,
      model: 'whisper-1',
      language: 'zh',
    })

    const userText = transcription.text
    console.log('ğŸ¤ èªéŸ³è½‰æ–‡å­—:', userText)

    // æ ¹æ“šç•¶å‰éšæ®µè™•ç†å°è©±
    let contextPrompt = userText
    
    // åœ¨ç‰¹å®šéšæ®µæ·»åŠ ä¸Šä¸‹æ–‡
    if (currentStage === 'practice-pitch' && generatedPitch) {
      contextPrompt = `å­¸ç”Ÿæ­£åœ¨ç·´ç¿’å‰›æ‰ç”Ÿæˆçš„ pitchã€‚ä»–å€‘èªªçš„å…§å®¹æ˜¯ï¼šã€Œ${userText}ã€\n\nåƒè€ƒ pitch ç¨¿ï¼š\n${generatedPitch}\n\nè«‹åœ¨ä»–å€‘ç·´ç¿’å®Œå¾Œï¼Œæº–å‚™é€²è¡Œè©•åˆ†ã€‚`
    }

    // åœ¨ free-description éšæ®µéœ€è¦åœ–ç‰‡ï¼ˆè®“ AI çœ‹åˆ°ä½œå“ï¼‰
    // å…¶ä»–éšæ®µå°ˆæ³¨æ–¼èªè¨€è¡¨é”ï¼Œä¸éœ€è¦åœ–ç‰‡
    const shouldSendImages = currentStage === 'free-description'

    const assistantReply = await sendMessageSimple(
      messages,
      contextPrompt,
      shouldSendImages && images.length > 0 ? images : undefined
    )

    console.log(`âœ… å°è©±å›æ‡‰å®Œæˆ ${shouldSendImages ? 'ï¼ˆå«åœ–ç‰‡ï¼‰' : 'ï¼ˆç´”æ–‡å­—ï¼‰'}`)

    // ç”ŸæˆèªéŸ³
    const speech = await openai.audio.speech.create({
      model: 'tts-1',
      voice: 'nova',
      input: assistantReply,
      speed: 0.95,
      response_format: 'mp3', // æ˜ç¢ºæŒ‡å®šæ ¼å¼
    })

    const audioBuffer = Buffer.from(await speech.arrayBuffer())
    const audioBase64 = audioBuffer.toString('base64')
    const audioUrl = `data:audio/mp3;base64,${audioBase64}`

    // åˆ¤æ–·æ˜¯å¦éœ€è¦è½‰æ›éšæ®µ
    let nextStage: ConversationStage | undefined

    // æ ¹æ“šå›æ‡‰å…§å®¹åˆ¤æ–·æ˜¯å¦è©²é€²å…¥ä¸‹ä¸€éšæ®µ
    if (currentStage === 'free-description') {
      // å­¸ç”ŸéŒ„éŸ³å®Œæˆå¾Œï¼Œç›´æ¥è½‰åˆ° qa-improve éšæ®µ
      // AI æœƒåœ¨é€™å€‹éšæ®µæå‡ºå•é¡Œ
      nextStage = 'qa-improve'
    } else if (currentStage === 'qa-improve') {
      // å­¸ç”Ÿå·²å›ç­”å•é¡Œï¼Œç›´æ¥é€²å…¥æ•´ç†éšæ®µ
      nextStage = 'confirm-summary'
    } else if (currentStage === 'confirm-summary' && (assistantReply.includes('Pitch') || assistantReply.includes('pitch'))) {
      // ç¢ºèªé‡é»å¾Œï¼Œç”Ÿæˆ Pitchï¼Œè½‰åˆ° generate-pitch éšæ®µ
      nextStage = 'generate-pitch'
    } else if (currentStage === 'practice-pitch') {
      // å­¸ç”Ÿå®Œæˆ pitch ç·´ç¿’ï¼Œè‡ªå‹•è§¸ç™¼è©•åˆ†
      nextStage = 'evaluation'
    } else if (currentStage === 'evaluation') {
      // è©•åˆ†å®Œæˆï¼Œè½‰åˆ°é¸æ“‡éšæ®µ
      nextStage = 'practice-again'
    }

    return NextResponse.json({
      transcription: userText,
      reply: assistantReply,
      audioUrl,
      nextStage,
    })
  } catch (error: any) {
    console.error('âŒ API éŒ¯èª¤:', error)
    console.error('éŒ¯èª¤å †ç–Š:', error.stack)
    
    let errorMessage = 'è™•ç†è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤'
    
    if (error.message?.includes('API key')) {
      errorMessage = 'OpenAI API Key è¨­å®šéŒ¯èª¤ï¼Œè«‹æª¢æŸ¥ç’°å¢ƒè®Šæ•¸'
    } else if (error.message?.includes('quota')) {
      errorMessage = 'OpenAI API é…é¡ä¸è¶³ï¼Œè«‹æª¢æŸ¥å¸³æˆ¶é¤˜é¡'
    } else if (error.message?.includes('model')) {
      errorMessage = 'AI æ¨¡å‹å‘¼å«å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦'
    } else if (error.message?.includes('éŸ³è¨Š')) {
      errorMessage = 'èªéŸ³è™•ç†å¤±æ•—ï¼Œè«‹é‡æ–°éŒ„éŸ³'
    }
    
    return NextResponse.json(
      {
        error: errorMessage,
        details: error.message,
        timestamp: new Date().toISOString(),
      },
      { status: 500 }
    )
  }
}
